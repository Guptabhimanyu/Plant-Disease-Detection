{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rv9lGBy0Nm91",
        "outputId": "93ca520b-310c-4a50-843f-14936bdcd9c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import urllib.request\n",
        "import os\n",
        "\n",
        "# Mount Google Drive to access the trained model\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import seaborn as sns\n",
        "import sys\n",
        "import os\n",
        "import tensorflow \n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from numpy import load\n",
        "from matplotlib import pyplot\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import backend\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D,MaxPooling2D,GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import BatchNormalization"
      ],
      "metadata": {
        "id": "Ny0Ucv4NOm5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the trained model from Google Drive\n",
        "model_path = '/content/drive/MyDrive/model2.h5' # modify with your model path\n",
        "model = keras.models.load_model(model_path)\n",
        "\n",
        "# Define the categories for your classes\n",
        "categories = ['Pepper,_bell___Bacterial_spot', 'Pepper,_bell___healthy', 'Potato___Early_blight', 'Potato___Late_blight', 'Potato___healthy']\n",
        " # modify with your class names\n",
        "\n",
        "# Open the video file\n",
        "video_path = '/content/drive/MyDrive/Potato Late Blight Preview ClipED.mp4' # modify with your video path\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Get the video dimensions and frame rate\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "# Create a video writer to save the predicted frames to a new video file\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter('/content/drive/MyDrive/predicted_video.mp4', fourcc, fps, (width, height))\n",
        "\n",
        "# Loop through the frames from the video\n",
        "while cap.isOpened():\n",
        "    # Read a frame from the video\n",
        "    ret, frame = cap.read()\n",
        "    \n",
        "    if not ret:\n",
        "        break\n",
        "    \n",
        "    # Resize the frame to the input shape of your model\n",
        "    img = cv2.resize(frame, (224, 224))\n",
        "    \n",
        "    # Preprocess the image to make it compatible with the model\n",
        "    img = img.astype('float32') / 255.0\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    \n",
        "    # Pass the image through the model and get the predicted class\n",
        "    pred = model.predict(img)\n",
        "    class_idx = np.argmax(pred[0])\n",
        "    class_name = categories[class_idx]\n",
        "    \n",
        "    # Draw the predicted class on the frame\n",
        "    cv2.putText(frame, class_name, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "    \n",
        "    # Write the predicted frame to the output video file\n",
        "    out.write(frame)\n",
        "    \n",
        "# Release the resources\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "8fEro7WUN7v0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the trained model from Google Drive\n",
        "model_path = '/content/drive/MyDrive/model2.h5' # modify with your model path\n",
        "model = keras.models.load_model(model_path)\n",
        "\n",
        "# Define the categories for your classes\n",
        "categories = ['Pepper,_bell___Bacterial_spot', 'Pepper,_bell___healthy', 'Potato___Early_blight', 'Potato___Late_blight', 'Potato___healthy'] # modify with your class names"
      ],
      "metadata": {
        "id": "PC-C0k6FfYnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "# Load the trained model\n",
        "model = load_model(model_path)\n",
        "\n",
        "# Define the function to preprocess the image\n",
        "def preprocess_image(img):\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "    img = np.array(img)\n",
        "    img = img.astype('float32')\n",
        "    img = img / 255.0\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    return img\n",
        "\n",
        "# Define the function to predict the class of the input image\n",
        "def predict_class(img):\n",
        "    preprocessed_img = preprocess_image(img)\n",
        "    predictions = model.predict(preprocessed_img)\n",
        "    class_idx = np.argmax(predictions)\n",
        "    return class_idx\n",
        "\n",
        "# Define the function to capture frames from the webcam and show the predicted class\n",
        "def webcam_predict():\n",
        "    # Start capturing frames from the webcam\n",
        "    cap = cv2.VideoCapture(2)\n",
        "\n",
        "    # Define the class labels\n",
        "    class_labels = ['Pepper,_bell___Bacterial_spot', 'Pepper,_bell___healthy', 'Potato___Early_blight', 'Potato___Late_blight', 'Potato___healthy'] \n",
        "\n",
        "    while True:\n",
        "        # Read a frame from the webcam\n",
        "        ret, frame = cap.read()\n",
        "\n",
        "        # Preprocess the frame and predict the class\n",
        "        img = preprocess_image(frame)\n",
        "        class_idx = predict_class(img)\n",
        "        class_label = class_labels[class_idx]\n",
        "\n",
        "        # Draw the predicted class label on the frame\n",
        "        cv2.putText(frame, class_label, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "\n",
        "        # Show the frame with the predicted class\n",
        "        cv2_imshow(frame)\n",
        "\n",
        "        # Exit the program if the user presses the 'q' key\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "    # Release the webcam and close all windows\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "# Call the webcam_predict() function to start the webcam prediction\n",
        "webcam_predict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "muqMWQ-JOv8I",
        "outputId": "49f960e9-62b6-47ff-ac67-47a02dea2f7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-c5d6fecad23c>\u001b[0m in \u001b[0;36m<cell line: 53>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;31m# Call the webcam_predict() function to start the webcam prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0mwebcam_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-c5d6fecad23c>\u001b[0m in \u001b[0;36mwebcam_predict\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# Preprocess the frame and predict the class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mclass_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mclass_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-c5d6fecad23c>\u001b[0m in \u001b[0;36mpreprocess_image\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Define the function to preprocess the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.7.0) /io/opencv/modules/imgproc/src/resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qvYNB3ICepkE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}